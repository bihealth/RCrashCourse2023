---
title: "R crash course / 04"
author: ""
date: "`r Sys.Date()`"
output:
  ioslides_presentation: 
    widescreen: true
    smaller: true
    css: files/style.css
    logo: files/logo_bihealth_en.png
---

```{r,echo=FALSE}
## Set default options for the knitr RMD processing
knitr::opts_chunk$set(echo=TRUE,eval=FALSE,warning=FALSE,message=FALSE,fig.width=5,fig.height=5,cache=FALSE,autodep=TRUE, results="hide")
knitr::opts_knit$set(root.dir = "../")
```

```{r, eval=TRUE, echo=FALSE, message=FALSE}
library(readxl)
library(beeswarm)
library(tidyverse)
library(sm)
library(zoo)
library(RColorBrewer)
```

## Aims for today

* Searching, sorting and selecting
* Matching and merging data
* Pipes - writing readable code
* Wide and long format

![](images/data-science.png){ width=600px }


# Selecting columns

## Selecting columns of data frames

If we want the actual column, we use the `$` operator:

```{r}
df <- data.frame(a=1:5, b=6:10, c=11:15, d=16:20)
df$a
```

However, what if we want to select multiple columns?

## Selecting multiple columns

First, the old way:

```{r}
# select columns 1 to 2
df2 <- df[ , 1:2]

# select anything but column 2
df2 <- df[ , -2]

# select columns a and c
df2 <- df[ , c("a", "c")]

# select columns a and c, but in reverse order
df2 <- df[ , c("c", "a")]
```

This is very similar to what we did when dealing with matrices, and
actually similar to how we select elements from a vector.

## Selecting columns using tidyverse

Tidyverse has the `select` function, which is more explicit and readable.
It also has extra features that make it easier to work with!

```{r}
library(tidyverse)
# select columns a and c
df2 <- select(df, a, c)

# select columns a to c
df2 <- select(df, a:c)

# select anything but column b
df2 <- select(df, -b)
```

Note: **This only works with tidyverse functions!"**

## Tidyverse and quotes


```{r}
select(df, a, c)
```

Note the lack of quotes around `a` and `c`! This is a feature in tidyverse which
has two effects:

 * it is easier to type (you save the typing of `df$""`!
   imagine how much time you have now)
 * it is confusing for beginners ("why are there no quotes?", "when should
   I use quotes and when not?", "how does it know that it is `df$a` and
   not some other `a`?") 
 * makes programming confusing (what if
   "a" holds the *name* of the column that you would like to sort by? -
   use `.data[[a]]`; Or is some other vector by which you wish to sort?)

## Exercise 4.1

 * Read the file 'Datasets/transcriptomics_results.csv'
 * What columns are in the file?
 * Select only the columns 'GeneName', 'Description', 'logFC.F.D1' and 'qval.F.D1'
 * Rename the columns to 'Gene', 'Description', 'LFC' and 'FDR'

# Sorting and ordering

## sort and order (base R - not covered in the course)

`sort` directly sorts a vector:

```{r eval=TRUE}
# randomize numbers 0.1, 0.2, ... 1
v <- sample(1:10)/10 
sort(v)

## decreasing 
sort(v, decreasing=TRUE)

## same as
rev(sort(v))
```

## sort and order cont.

However, `order` is more useful. It returns the *position*
of a value in a sorted vector.

```{r eval=TRUE, results="markdown"}
order(v)
order(v, decreasing=TRUE)
```

Think for a moment what happens here.


## sort and order cont.

`sort` and `order` can be applied to character vectors as well:

```{r, eval=TRUE, results="markdown"}
l <- sample(letters, 10)
sort(l)
order(l, decreasing=TRUE)
```

Note that sorting values turned to a character vector will not give
expected results:

```{r, eval=TRUE, results="markdown"}
v <- sample(1:200, 15)
sort(as.character(v))
```

## Using order to sort the data

We can use the return value of `order` to sort the vector:

```{r eval=TRUE,results="markdown"}
v <- sample(1:10)/10 
v[ order(v) ]
```

This is the same as `sort(v)`, but has a huge advantage: we can use it sort
*another* vector, matrix, list, data frame etc.


## Sorting data frames (using order)

To sort a data frame according to one of its columns, we use `order` and
then select rows of a data frame based on that order. That is the "classic"
way of sorting.

```{r}
df <- data.frame(id=paste0("ID", 1:10), val=rnorm(10))
ord <- order(df$val)
df[ ord, ]
df[ order(df$val, decreasing=TRUE), ]
df[ order(abs(df$val), decreasing=TRUE), ]
```

For numeric values, instead of `decreasing=TRUE`, you can just order by
`-abs(df$val)`.

## Sorting data frames with tidyverse

Sorting with tidyverse is easier (but comes at a cost -
you need to know tidyverse functions):

```{r}
arrange(df, val)

## reverse sort
arrange(df, desc(val)) 

## largest absolute values first
arrange(df, desc(abs(val))) 
```

Note: **no quotes around column names!**

## Why both?

 * `order` is more flexible and can be used for any type of data
 * `arrange` is easier to use and is more readable, but only works with
   data frames

You should know both!

## Example

```{r, eval=TRUE}
## read the transcriptomic results data set
res <- read_csv("Datasets/transcriptomics_results.csv")

## only a few interesting columns
res <- select(res, GeneName, Description, logFC.F.D1, qval.F.D1)

## use new column names
colnames(res) <- c("Gene", "Description", "LFC", "FDR")
```

*Data from: Weiner, January, et al. "Characterization of potential
biomarkers of reactogenicity of licensed antiviral vaccines: randomized
controlled clinical trials conducted by the BIOVACSAFE consortium."
Scientific reports 9.1 (2019): 1-14.*

## Example cont.

```{r}
## order by decreasing absolute logFC
res <- arrange(res, desc(abs(LFC)))
plot(res$LFC[1:250], type="b")

# base R
# ord <- order(abs(res$LFC), decreasing=TRUE)
# res <- res[ord, ]

## then, order by p-value
res <- arrange(res, FDR)
plot(abs(res$LFC[1:250]), type="b")
plot(res$FDR[1:250], type="b", log="y")
```

# Filtering and subsetting

## Filtering of data frames

There are two ways, both simple. In both of them, you need to have a
logical vector that indicates which rows to keep and which to remove.

```{r eval=FALSE}
keep <- res$FDR < 0.05
res[ keep, ]

## or, with tidyverse:

filter(res, FDR < 0.05)
```

**Note:** again, we don't use quotes around column names!

## Excercise 4.2

 * Load the example transcriptomic data (`transcriptomics_results.csv`)
 * Inspect the data frame. 
   * `qval` stands for false discovery rate (p-value corrected with Benjamini-Hochberg method)
   * `logFC` is log~2~ fold change
   * `D0`..`D3` is day 0 to day 3
 * Pick a day to work with (D1 is a good choice)
 * Try sorting of the data frame; by gene name, by identifier, by log fold
   change, by absolute log fold change (you can use any method)
 * Create a new data frame which contains only genes which have
   significant down-regulation (qval < 0.05 and log~2~FC < 0)
 * How many genes are significantly down-regulated?
 * Order the new data frame by Gene name (A-Z)

# Searching and subsetting

## Searching through data frames

With `%in%`, it is easy to select keywords matching a set.

```{r}
interferon <- c("TAP1","IFIH1","IRF7","PARP9","STAT1","PLSCR1",
                "IFITM1","HERC5","DDX60","USP18","RSAD2","IFIT1")
sel <- res$Gene %in% interferon
res[ sel, ] ## or: filter(res, Gene %in% interferon)
```


## Searching for patterns

What if we don't know the exact name, or if we want to match a more general
pattern? 

For this, we can use `grepl()` (which returns a logical vector) or `grep()`
(which is the same as `which(grepl())`).


```{r}
int <- grep("Interferon", res$Description)
length(int) # no matches

int <- grep("Interferon", res$Description, ignore.case=TRUE)
head(int)
head(res[int, ])
```

## More regular expressions

```{r}
## search for GBP1, GBP2, GBP3, 
## but not GBP12 or pseudo-GBP1
sel <- grep("^GBP[123]$", res$Gene)
res[ sel, ]

## search for either cytokine or chemokine
sel <- grep("(cytokine|chemokine)", res$Description, ignore.case=TRUE)
length(sel)
head(res[ sel, ])
```

## More regular expressions (cont.)

We can use the parentheses for substitution as well. Please don't mind that
weird `\\1`, just learn it.

Remember â€“ `.*` means any character (`.`) any number of times (`*`).
`[0-9]*` means any digit (`[0-9]`) any number of times (`*`).

```{r}
## say we only want the middle part
a <- c("ID-1-2020", "ID-3-2019", "ABC-4-2018")

## extract the middle part
gsub(".*-(.*)-.*", "\\1", a)
```

## Logical operators `&` and `|`

Logical vectors can be combined using the logical operators `&` ("and"),
`|` ("or").


```{r}
l1 <- c(TRUE, TRUE)
l2 <- c(FALSE, TRUE)
l3 <- c(TRUE, FALSE)
l4 <- c(FALSE, FALSE)

l2 | l3
l2 & l3
l1 & l2
l1 | l4
```

## Combining logical vectors

We can use the logical vectors to select rows from a data frame, and with
the logical operators, we can combine conditions.

For example: show only significant (qval < 0.01) and up-regulated (log~2~
fold change > 0) genes:

```{r}
sel <- res$p.value < 0.01 & res$LFC > 0
head(res[ sel, ])
```

*Note:* for long data frames, head shows only the first 6 rows.`



## Combining searches

We can also use the logical operators (`&` and `|`) to combine searches.
For this, we use `grepl()` rather than `grep()`. `grep()` returns a vector
of indices, while `grepl()` returns a vector of logical values.

```{r}
sel <- res$Gene %in% interferon
significant <- abs(res$LFC) > 1 & res$p.value < 0.05
sel <- sel & significant

res[sel, ] ## or: filter(res, sel)
```

*Note: More on the `filter()` function and other tidyverse functions later.`*

## Filtering with multiple conditions

```{r}
keep <- res$FDR < 0.05 & abs(res$LFC) > 1
res[ keep, ]

## or, with tidyverse:
filter(res, FDR < 0.05, abs(LFC) > 1)
filter(res, FDR < 0.05 & abs(LFC) > 1)
```


## Excercise 4.3

Continue with the data frame from exercise 4.2

 * Create a data frame which contains only genes which have significant
   differences at qval < 0.05 and abs(log2FC) > 1.5.
 * Search for ribosomal genes. How many did you find?
 * Create a data frame which contains only genes that are not "Other" or
   "Unknown".
 * Find all significantly upregulated cytokines.
 * How many interleukine genes are significantly down-regulated?

# Matching data sets

## Finding common IDs

We can use `intersect()` for that.

```{r}
set1 <- letters[1:5]
set2 <- letters[3:7]
intersect(set1, set2)
```


## Merging

A better, but more complex solution to merge two data frames is the
`merge()` function.

Some SQL terminology:

 * inner join: we are merging only common elements
 * outer join: we are making sure that elements from both sets are taken
   over
 * left outer join: same, but only for the first set
 * right outer join: same, but only for the second set

## Merging: create example data frames

```{r}
df1 <- data.frame(ID=sample(letters, 15), value1=rnorm(15))
df2 <- data.frame(ID=sample(letters, 15), value2=rnorm(15))
```


## Merging (cont.)

Usage of the `merge()` function:

```{r}
merge(df1, df2) # inner join by default
merge(df1, df2, all.x=TRUE) # left outer join
merge(df1, df2, all.y=TRUE) # right outer join
merge(df1, df2, all=TRUE) # outer join
```

Note: tidyverse contains functions `inner_join`, `outer_join` etc. which
look slightly more specific (but do the same).

## Merging (cont.)

The `by`, `by.x` and `by.y` parameters tell `merge` which columns contain
the identifiers by which to join. It is always safer to specify this
parameter!

```{r}
df1 <- data.frame(ID=c("a", "a", "b", "c"), no=c(1, 2, 3, 4), 
  value=rnorm(4))
df2 <- data.frame(ID=c("a", "a", "b", "c"), no=c(1, 2, 3, 4), 
  value=rnorm(4))
merge(df1, df2)           ## not what we wanted
merge(df1, df2, by="ID")  ## not what we wanted
merge(df1, df2, by=c("ID", "no"))

inner_join(df1, df2, by = c("ID", "no")) # tidyverse option
```

## Merging (cont.)

A simpler (but requiring more steps) alternative would be to make a new
identifier:

```{r}
df1$ID2 <- paste(df1$ID, df1$no, sep=".")
df2$ID2 <- paste(df2$ID, df2$no, sep=".")
merge(df1, df2, by="ID2")
```

## Another example

```{r}
df1 <- data.frame(subject.id=1:3, sex=c("M", "F", "F"), 
  age=c(28, 35, 29))
df2 <- data.frame(subject.id=rep(1:3, each=2), 
  timepoint=rep(1:2, 3), value=rnorm(6))
merge(df1, df2, by="subject.id")
```


## Excercise 4.3

The files `expression_data_vaccination_example.xlsx` and
`labresults_full.csv` contain data from the same study.

 1. read the first sheet from the XLSX file and the CSV file.
 3. Which columns ID the subjects? Are there any subjects in common? How do
    you match the subjects?
 5. We are interested only in the following information: Subject ID, ARM
    (group), Time point, sex, age, test name and the actual measurement.
    Are the measurements numeric? Remember, you can use expressions like `[ , c("ARM", "sex") ]` 
    to select the desired columns from a data set.
 4. Use the subjects to merge the two data frames however you see fit. Note
    that there are multiple time points per subject and multiple
    measurements per subject and time point.

# Pipes in R

## Remember functions?

 * Each function has an input and an output
 * What function returns can be used as input to another function
 * The following are equivalent:

Step by step:

```{r}
a <- read_csv("file.csv")
b <- clean_names(a)
```

All in one go - without saving intermediate results:


```{r}
b <- clean_names(read_csv("file.csv"))
```

This can quickly become unreadable!

## Nested function calls vs piping

```{r eval=TRUE, echo=FALSE, message=FALSE}
library(janitor)
iris <- read_csv("Datasets/iris.csv")
iris <- clean_names(iris)
```


```{r}
# from Exercise 3.3
iris$petal_length <- trimws(iris$petal_length)
iris$petal_length <- gsub("[a-z]", "", iris$petal_length) 
iris$petal_length <- gsub(",", ".", iris$petal_length)
iris$petal_length <- as.numeric(iris$petal_length)
```

We could do it all on one line:


```{r}
iris$petal_length <- as.numeric(
  gsub(",", ".", 
    gsub("[a-z]", "", 
      trimws(iris$petal_length)
    )
  )
)
```

However, this is hard to read and maintain.

## Pipes

Fortunately, there is a *dirty* trick that results in clean and readable
code:

```{r}
iris$petal_length <- iris$petal_length |> 
  str_remove("[a-z]", "") |> 
  str_replace(",", ".") |> 
  as.numeric()
```

Basically, `a |> f(b)` is the same as `f(a, b)`.

*Note 1:* Rather than gsub, we use the `str_remove` and `str_replace`
functions from the `stringr` package. This would not work with gsub!

*Note 2:* in the older versions of R (earlier than 4.1.0), you can use the
`magrittr` package to achieve the same effect using the `%>%` operator.

# Wide and long format

## Wide and Long format (demonstration)

 * https://youtu.be/NO1gaeJ7wtA (introduction, 9 minutes)
 * https://youtu.be/v5Y_yrnkWIU (wide to long, 6 minutes)
 * https://youtu.be/jN0CI62WKs8 (long to wide, 4 minutes)


## Wide and Long format

 Long advantages:

  * easier to filter, process, visualize, do statistics with
  * focused on measurement ("patient ID" or equivalent is a covariate, and so is measurement type)
 
 Wide advantages:

  * groups data by a covariate ("patient ID")
  * can be easier to manage (each column one measurement type)

## Converting from wide to long:

```{r}
wide <- read.table(header=TRUE, text='
 subject sex control cond1 cond2
       1   M     7.9  12.3  10.7
       2   F     6.3  10.6  11.1
       3   F     9.5  13.1  13.8
       4   M    11.5  13.4  12.9
')
pivot_longer(wide, cols=c("control", "cond1", "cond2"), 
  names_to="condition", values_to="measurement")
```



## Converting from long to wide

```{r}
long <- read.table(header=TRUE, text='
 subject  sampleID sex condition measurement
       1  ID000001 M   control         7.9
       1  ID000002 M     cond1        12.3
       1  ID000003 M     cond2        10.7
       2  ID000004 F   control         6.3
       2  ID000005 F     cond1        10.6
       2  ID000006 F     cond2        11.1
       3  ID000007 F   control         9.5
       3  ID000008 F     cond1        13.1
       3  ID000009 F     cond2        13.8
')
```

## Converting from long to wide

```{r}
## not what we wanted!!! Why?
pivot_wider(long, names_from="condition", values_from="measurement")

## Instead: 
pivot_wider(long, id_cols="subject", names_from="condition", values_from="measurement")
```

## Exercise 4.1

Convert the following files to long format:

 * `labresults_wide.csv`
 * The iris data set (`data(iris)`)
 * `cars.xlsx` (tricky!)

Clean up and convert to long format (what seems to be the problem? How do
we deal with that?):

 * `mtcars_wide.csv`


